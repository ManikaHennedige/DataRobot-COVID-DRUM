## DRUM-Compatible Model and Environment

## Introduction
This repository comprises 2 folders. The first folder, called 'environment', contains the Docker context files required to create a Docker environment that would be used to test the created model. This environment would subsequently be uploaded to DataRobot. The second folder, called 'model', contains a few files (including the necessary custom.py and .h5 model files) that are required for the creation of a DRUM-compatible model.

Note that DRUM requires a Linux environment. If on Windows, use Windows Subsystem for Linux (WSL)

### DRUM-Compatible Environment
Most of the files inside wouldn't need to be changed.

#### environment/requirements.txt
If there are any additional dependencies that aren't covered in the 'environment/requirements.txt' file, add them before continuing.

### DRUM-Compatible Model
This is the model file that can be uploaded and deployed to DataRobot

#### custom.py
This file was autogenerated using a DRUM utility, and essentially came with a few supported, commented-out functions that can be used with DRUM. Input data streams can be manipulated and converted to a desired file type. This file is necessary if any additional data manipulation is required (which is pretty much always...).

#### .h5 model file
This is the model file. The logic for loading this file is inside the load_model hook in custom.py

#### utils/
This folder contains code that has been abstracted for easier calling within custom.py

## Use

### Installing DRUM
Although DRUM is installed as a pip package, I've found that it needs to be installed in the global environment to work. My workflow was to install DRUM in the global environment, then create a virtual environment afterwards. Note that a virtual environment is not really needed if testing with the DRUM-Compatible environment as the dependencies all have to be installed in the environment (and not on your virtual environment).

DRUM can be installed from a Linux terminal (or WSL on Windows) by running the following command:
```pip install datarobot-drum```

### Running the custom model in the custom environment in server mode (supporting real-time predictions)
Run the following command to run the model using DRUM inside a Docker environment that DRUM creates using the Docker context files provided in the Environment/ folder:

```drum server --code-dir model/ --positive-class-label 1 --negative-class-label 0 --target-type binary --address localhost:6789 --docker environment/```

#### positive-class and negative-class
Should correspond with the format of the output predictions that are being rendered

#### address
The port number can be anything, just avoid commonly used ones like 443, 80, etc. In this case the server is running on localhost:6789

#### --docker
Specifies the location of the Docker context files. Alternatively, you could build a Docker image and specify the location of the tarball

### Making predictions
For this model, there are 2 inputs:
1. Image file
- Image (usually .png) file containing the CT Scan that is being predicted

1. Label file
- Label (usually .txt) file containing information about the image (i.e. bounding box, ground truth label, associated file name) in each line. In this case we are only going for single real-time predictions; there is always only one line of data present in this file

To cater to this, the server accepts input in the HTML form-data parameter, with 'X' as the key and a file as the value.
A zip file containing an image file and label file should be provided in the abovementioned data parameter. The files should follow the following naming conventions:
1. Image file: image.png
1. Label file: label.txt
1. Zip Archive: data.zip (not necessary)

This can be accomplished with API testing tools like Postman.


