## DRUM-Compatible Model and Environment

## Introduction

DRUM, or DataRobot User Models, provide a way for users to test custom models and environments before they are uploaded and deployed to the DataRobot platform. This repository comprises 3 main folders, with each folder performing its' own distinct function.

1. 'environment' folder

    This folder contains the Docker context files that are required to create the Docker environment used to run the model in.

1. 'model' folder

    This folder contains files required to create a DR-compatible model.

1. 'app' folder

    This folder contains files for the running of a couple of CLI interface application to generate prediction files and perform predictions using the created environment and model.


## Folder Details

### 'environment' folder

This folder was obtained through copying a folder from <a href="https://github.com/datarobot/datarobot-user-models/tree/master/public_dropin_environments/python3_keras">DataRobot's DRUM repository</a>

The function and purpose of the files are outlined below:

1. Dockerfile

    Contains the necessary prerequisites (such as Python version) that are needed to create the environment. Make amendments as necessary.

1. dr_requirements.txt

    Contains the requirements for the base DataRobot environment. If the Dockerfile's initial import in the Dockerfile does not need to be changed, chances are the dependencies in this file won't need to be changed either.

1. requirements.txt

    Contains the requirements for running the custom user-defined environment. Any packages/dependencies that are used by the 'model' folder should be specified here


### 'model' folder

This folder was generated by running:

```drum new model --language python --code-dir model```

1. utils

    Folder containing optional utility files and scripts. Code scripts and other files can be placed here. This folder currently only contains a single 'functions.py' script, which contain functions that are called in 'custom.py'

1. custom.py

    Script that executes when a custom model is run via DRUM/DataRobot. The functions execute in sequence if they are not commented out. The template for this file is autogenerated using the above command.

1. phase-1.h5

    Model weights that are loaded into DRUM/DataRobot using the custom.py file.

### 'app' folder

This folder contains two CLI applications that can be run to generate data, then perform predictions with the DataRobot/DRUM API.

1. 'data' folder

    This directory contains several folders, with each folder containing an example instance of data that can be predicted by DataRobot/DRUM. Only the 'data.txt' file is required as a prerequisite. The other csv files are generated by the script 'load.py'.

1. load.py

    This script is customized for use with the COVID CT-Scan project. It allows users to generate 3 csv files based on a 'data.txt' file, which can then be uploaded to DataRobot for testing and data quality metric tracking. This script requires all COVID data images to be accessible at a specified location.

1. predict.py

    This script is adapted from the official DR script, as is more generally usable. It allows real-time predictions to be made on the DataRobot or DRUM platform.

## Prerequisites

Note that DRUM requires a Linux environment to run. If on Windows, use Windows Subsystem for Linux (WSL)

### Installing DRUM
DRUM should be installed in the global Python environment (within Linux/WSL on Windows):

```pip install datarobot-drum```

### Creating a virtual environment (optional)
A virtual environment may be created after installing DRUM:

```virtualenv wsl_env```

```source wsl_env/bin/activate```

Scripts run in this virtual environment will usually only come from the 'app' folder - dependencies in the 'environment' folder do not necessarily need to be installed here. Install requirements located in the 'app' folder

```pip install app/requirements.txt```

## Use

### Loading data into compatible csv files

The 'load.py' file contains scripts // stopped here

### Running the custom model in the custom environment in server mode (supporting real-time predictions)
Run the following command to run the model using DRUM inside a Docker environment that DRUM creates using the Docker context files provided in the Environment/ folder:

```drum server --code-dir model/ --target-type binary --positive-class-label '1' --negative-class-label '0' --address localhost:6789 --docker environment```

#### address
The port number is up to user's discretion. In this case the server is running on localhost:6789

#### --docker
Specifies the location of the Docker context files. Alternatively, you could build a Docker image and specify the location of the tarball

### Making predictions
For this model, there are 2 inputs:
1. Image file
    - Image (usually .png) file containing the CT Scan that is being predicted

1. Label file
    - Label (usually .txt) file containing information about the image (i.e. bounding box, ground truth label, associated file name) in each line. In this case we are only going for single real-time predictions; there is always only one line of data present in this file

To cater to this, the server accepts input in the HTML form-data parameter, with 'X' as the key and a file as the value.
A zip file containing an image file and label file should be provided in the abovementioned data parameter. The files should follow the following naming conventions:
1. Image file: image.png
1. Label file: label.txt
1. Zip Archive: data.zip (not necessary)

This can be accomplished with API testing tools like Postman.

## Uploading to DataRobot
### Creating a new Custom Environment
Create a new custom environment from the DataRobot UI, then drop the 'environment.zip' file into the 'Docker context' field. The environment will be created using the context provided.

### Creating a new custom Model
Create a new model, making sure to choose the target type as unstructured. Use the 'file upload' feature instead of the folder upload feature to ensure that the custom.py and model.h5 files are accessible from the root directory. The 'folder upload' feature can be used for dependencies (e.g. in this case the 'utils' folder can be uploaded via this method).

Test the model, then deploy.


