# from preprocessing import load_labels
import pandas as pd
import numpy as np
from utils.functions import load_labels, data_constructor
import tensorflow as tf
import os
from PIL import Image
import io
import zipfile
import shutil
#
#"""
#This file was autogenerated by: drum new model --language python
#Generation date: Sun Oct 29 17:25:17 2023
#
#Note: this is an example of custom.py file.
#    Below are all the hooks you can use to provide your own implementation.
#    All hooks are currently commented out so uncomment a hook function in 
#    order to use it.
#"""
#
#
def init(**kwargs):
   """
   This hook can be implemented to adjust logic in the training and scoring mode.
   init is called once the code is started.

   :param kwargs: additional keyword arguments to the function.
   code_dir - code folder passed in --code_dir argument
   """

   pass


def load_model(code_dir):
   """
   This hook can be implemented to adjust logic in the scoring mode.

   load_model hook provides a way to implement model loading your self.
   This function should return an object that represents your model. This object will
   be passed to the predict hook for performing predictions.
   This hook can be used to load supported models if your model has multiple artifacts, or
   for loading models that drum does not natively support

   :param code_dir: the directory to load serialized models from
   :returns: Object containing the model - the predict hook will get this object as a parameter
   """

   # route to the hrnet log files and weights
   phase1_model = tf.keras.models.load_model(os.path.join(code_dir, "phase-1.h5"))
   print("loaded model...")

   # Returning a string with value "dummy" as the model.
   return phase1_model


def read_input_data(input_binary_data):
   """
   This hook can be implemented to modify reading input data, e.g. decode using custom charset.

   This function should return a dataframe, which will be passed into the transform hook.
   If it returns something other than a DF, you'll need to write your own score method.

   :param input_binary_data: input data as bytes
   :returns: a dataframe
   """

   
   def load_files(binary_data):

      if os.path.exists('received'):
         shutil.rmtree('received')

      os.makedirs('received/labels')
      os.makedirs('received/images')
      

      with zipfile.ZipFile(io.BytesIO(binary_data), "r") as zipf:
         zipf.extractall("received")
      
      image_path = 'received/image.png'
      label_path = 'received/label.txt'
      dest_image_folder = 'received/images/'
      dest_label_folder = 'received/labels/'

      shutil.move(image_path, dest_image_folder)
      shutil.move(label_path, dest_label_folder)
   
   load_files(input_binary_data)
   fnames_test, classes_test , bboxes_test = load_labels(label_file='received/labels/label.txt', image_folderpath='received/images/')
   densenet_x, densenet_y = data_constructor(fnames_test, classes_test, dim_size=(128,128) , index  = [0] , bboxes = bboxes_test)
   densenet_x = tf.keras.applications.densenet.preprocess_input(densenet_x)

   return densenet_x



#def transform(data, model):
#    """
#    This hook can be implemented to adjust logic in the scoring mode.
#
#    transform(data: DataFrame, model: Any) -> DataFrame
#
#    Intended to apply transformations to the prediction data before making predictions.
#    This is most useful if drum supports the model's library, but your model requires additional
#    data processing before it can make predictions
#
#    :param data: dataframe given to drum to make predictions on
#    :param model: is the deserialized model loaded by drum or by load_model hook , if supplied
#    :returns: a dataframe after transformation needed
#    """
#    return data
#
#
def score(data, model, **kwargs):
   
   """
   This hook can be implemented to adjust logic in the scoring mode.

   This method should return predictions as a dataframe with the following format:

   Binary Classification:
   Must have columns for each class label with floating-point class probabilities as values.
   Each row should sum to 1.0

   Regression:
   Must have a single column called "Predictions" with numerical values

   This hook is only needed if you would like to use drum with a framework not natively
   supported by the tool.

   :param data: the dataframe to make predictions against. If transform is supplied, data
       will be the transformed data.
   :param model: is the deserialized model loaded by drum or by load_model hook, if supplied
   :param kwargs: additional keyword arguments to the function. If model is binary classification,
   positive_class_label and negative_class_label will be provided in kwargs. If the model is multiclass
   classification (at least 3 classes), a class_labels list will be provided as a parameter.
   :returns: a dataframe, see documentation above on the structure of the dataframe to return.
   """
   pred = model.predict(data)
   pred = np.rint(pred).astype("int")
   pred = pred.reshape(1)
   print(pred)

   if pred == 1:
        data = {'0': [0.0], '1': [1.0]}
   else:
      data = {'0': [1.0], '1': [0.0]}

   df = pd.DataFrame(data)

   return df


#def post_process(predictions, model):
#    """
#    This hook can be implemented to adjust logic in the scoring mode.
#
#    This method should return predictions as a dataframe with the following format:
#
#    Binary Classification:
#    Must have columns for each class label with floating- point class probabilities as values.
#        Each row should sum to 1.0
#
#    Regression:
#    Must have a single column called `Predictions` with numerical values
#
#    This method is only needed if your model's output does not match the above expectations
#
#    :param predictions: is the dataframe of predictions produced by `cmrun` or by the
#        `score` hook, if supplied
#    :param model: the deserialized model loaded by `cmrun` or by `load_model`, if supplied
#    :returns: dataframe with the results to return
#    """
#    return predictions
#
#def fit(X, y, output_dir, **kwargs):
#
#    """
#    This hook must be implemented with your fitting code, for running drum in the fit mode.
#
#    Parameters
#    ----------
#    :param X: pd.DataFrame - training data to perform fit on
#    :param y: pd.Series - target data to perform fit on
#    :param output_dir: str - the path to write output. This is the path provided in '--output' parameter of the 'drum fit' command.
#    :param kwargs: Dict[str, Any] - additional optional keyword arguments to the function:
#        - 'class_order': [List[str] - a two element long list dictating the order of classes which should be used for modeling
#        - 'row_weights': np.ndarray - an array of non-negative numeric values which can be used to dictate how important a row is
#
#    :returns: nothing
#    """
#    return None