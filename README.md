## DRUM-Compatible Model and Environment

## Introduction
This repository comprises 2 folders. The first folder, called 'environment', contains the Docker context files required to create a Docker environment that would be used to test the created model. This environment would subsequently be uploaded to DataRobot. The second folder, called 'model', contains a few files (including the necessary custom.py and .h5 model files) that are required for the creation of a DRUM-compatible model.

Note that DRUM requires a Linux environment to run. If on Windows, use Windows Subsystem for Linux (WSL)

### DRUM-Compatible Environment
Only some of the files in this folder would need to be edited - most of it is necessary boilerplate for the creation of the environment

#### environment/requirements.txt
Contains a list of all packages that will be installed and available within the environment. Note that some packages require some additional dependencies to be installed directly (from the Dockerfile) before they will work. Any additional dependencies that aren't included in the base 'environment/requirements.txt' file should be added before proceeding.

### DRUM-Compatible Model
This is the model file that can be uploaded and deployed to DataRobot. Ensure that the directory structure shown is strictly adhered to.

#### custom.py
The skeleton/backbone of this file was autogenerated using a DRUM utility, and came with a few functions that are supported by DRUM. 
Input data streams can be manipulated and converted to a desired file type. 
This file is necessary if any additional data/model manipulation is required.

#### .h5 model file
This is the model file. The logic for loading this file is inside the load_model hook in custom.py

#### utils/
This folder contains code that has been abstracted for easier calling within custom.py

## Use

### Installing DRUM
Although DRUM is installed as a pip package, I've found that it needs to be installed in the global environment to work. My workflow was to install DRUM in the global environment, then create a virtual environment afterwards. Note that a virtual environment is not really needed if testing with the DRUM-Compatible environment as the dependencies all have to be installed in that environment (and not on your virtual environment).

DRUM can be installed from a Linux terminal (or WSL on Windows) by running the following command:
```pip install datarobot-drum```

### Running the custom model in the custom environment in server mode (supporting real-time predictions)
Run the following command to run the model using DRUM inside a Docker environment that DRUM creates using the Docker context files provided in the Environment/ folder:

```drum server --code-dir model/ --target-type binary --positive-class-label '1' --negative-class-label '0' --address localhost:6789 --docker environment```

#### address
The port number is up to user's discretion. In this case the server is running on localhost:6789

#### --docker
Specifies the location of the Docker context files. Alternatively, you could build a Docker image and specify the location of the tarball

### Making predictions
For this model, there are 2 inputs:
1. Image file
    - Image (usually .png) file containing the CT Scan that is being predicted

1. Label file
    - Label (usually .txt) file containing information about the image (i.e. bounding box, ground truth label, associated file name) in each line. In this case we are only going for single real-time predictions; there is always only one line of data present in this file

To cater to this, the server accepts input in the HTML form-data parameter, with 'X' as the key and a file as the value.
A zip file containing an image file and label file should be provided in the abovementioned data parameter. The files should follow the following naming conventions:
1. Image file: image.png
1. Label file: label.txt
1. Zip Archive: data.zip (not necessary)

This can be accomplished with API testing tools like Postman.

## Uploading to DataRobot
### Creating a new Custom Environment
Create a new custom environment from the DataRobot UI, then drop the 'environment.zip' file into the 'Docker context' field. The environment will be created using the context provided.

### Creating a new custom Model
Create a new model, making sure to choose the target type as unstructured. Use the 'file upload' feature instead of the folder upload feature to ensure that the custom.py and model.h5 files are accessible from the root directory. The 'folder upload' feature can be used for dependencies (e.g. in this case the 'utils' folder can be uploaded via this method).

Test the model, then deploy.


